# Lesson 08

* [Download the HTML file for this lesson](/lessons/08.html?raw=true)
* [Previous lesson](/lessons/07.md)
* [Next lesson](/lessons/09.md)
* [Back to lesson listing](/lessons/README.md)

## What is a texture?

A texture is a 2-dimensional chunk of memory that a WebGL program can read from. You should think of
it as image memory, where every point in a 2-dimensional grid of pixels has an r, g, b, and a value.
You don't *have* to use the data in a texture as an image, but that's definitely the most common
usage.

Here are the general steps in setting up and using a texture. I'll explain each one in more detail.

1. Create the texture with `gl.createTexture`.
1. Bind the texture to a texture unit with `gl.bindTexture`.
1. Load image data into the texture with `gl.texImage2D`.
1. Change the texture settings with `gl.texParemeter` (covered in Lesson 09).
1. Generate mipmaps with `gl.generateMipmap` (covered in Lesson 09).
1. Set the value of a sampler uniform to the unit that the texture was bound to in step 2.
1. Within the shader, sample from the texture using the sampler uniform and the `texture2D`
function.

Throughout this lesson, you'll see `gl.TEXTURE_2D` passed as an argument to a lot of methods. Don't
get excited: there's no 1D or 3D textures. The only alternative is texture cubes, which we'll cover
in Lesson 10.

## Texture units and binding

It shouldn't surprise you that using textures is not as simple as writing to a place in memory in
JavaScript, then reading from that place in memory within your shader. There are a couple layers of
indirection involved. I've never seen it explained very clearly, so here's my attempt.

WebGL has a number of slots, called "units", that a texture can be bound to. The first unit is
numbered `gl.TEXTURE0`, the second `gl.TEXTURE0 + 1`, and so on. The minimum requirement is 8
units, but there are often more. The first 32 slots can also be referred to using `gl.TEXTURE1`,
`gl.TEXTURE2`, through `gl.TEXTURE31`. Beyond that you have to use `gl.TEXTURE0 + 32`.

At any given time, one of these units is the active unit. You can imagine an arrow pointing from
JavaScript to the currently active unit. By default the arrow points to `gl.TEXTURE0`, and you can
change where it's pointing at any time with `gl.activeTexture`. For instance, the following changes
the active unit to `gl.TEXTURE2` (that is, it moves the arrow so it's pointing at a new slot):

	gl.activeTexture(gl.TEXTURE2)

Understand that so far we're talking about *units*, not *textures*. In order to do anything useful,
you need to bind a texture to a unit. `gl.bindTexture` will bind a texture to the currently active
unit. The following creates a texture and binds it to `gl.TEXTURE7`:

	var tobj = gl.createTexture()
	gl.activeTexture(gl.TEXTURE7)
	gl.bindTexture(gl.TEXTURE_2D, tobj)

Binding a texture to a unit simply means that whenever you do a texture operation, it will be
applied to whatever texture is bound to the currently active unit. Binding doesn't necessarily last
forever. Textures can be unbound and rebound to units as often as you like. You can even bind a
texture to more than one unit at the same time. Furthermore, being unbound doesn't destroy a
texture. It'll still maintain all its data and settings. You just need to bind it to a unit before
you can use it.

A unit can only have one texture bound to it at a time. If a texture is bound to a unit, and you
bind a different texture to that unit, the original texture is unbound from it. You can also unbind
a texture from a unit by binding `null`, *or* by deleting the texture. Unlike unbinding, of course,
deleting a texture actually destroys its data and settings, and it prevents you from using it again:

	gl.bindTexture(gl.TEXTURE_2D, null)
	gl.deleteTexture(tobj)

Unlike program objects and shader objects, texture objects often take up a significant amount of
memory, so it may be a good idea to actually delete them, but this is not always necessary either.
I've found WebGL to be good about being able to handle lots of unused, unbound textures. In addition
to `gl.deleteTexture`, textures are deleted when the underlying JavaScript texture object is
destructed. This happens if the texture is not bound to any unit, and all references to the object
are deleted, either through `delete tobj`, or going out of scope.

## Loading image data

Here's an example line that loads some image data (called `img`) into a texture:

	gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, img)

We'll talk about the arguments in a minute, but notice than nowhere in this line does it say which
texture you're loading the data into. It doesn't even give a unit. How does it know which texture
will receive this data? It's the texture that is bound to the currently active unit. It doesn't need
to be the most recently referenced texture. Consider the following lines:

	var tobj1 = gl.createTexture()
	var tobj2 = gl.createTexture()
	gl.activeTexture(gl.TEXTURE7)
	gl.bindTexture(gl.TEXTURE_2D, tobj1)
	gl.activeTexture(gl.TEXTURE11)
	gl.bindTexture(gl.TEXTURE_2D, tobj2)
	gl.activeTexture(gl.TEXTURE7)
	gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, img)

We create two texture objects, `tobj1` and `tobj2`. We bind `tobj1` to `gl.TEXTURE7`, and we bind
`tobj2` to `gl.TEXTURE11`. Then we switch the active texture back to `gl.TEXTURE7`, and call
`gl.texImage2D` to load the data. So which texture will receive the data? If you said `tobj1`,
you're right.

Okay, I hope it's clear how units and binding work. I know I really belabored that point, but like I
said, I've always found it confusing. Let's move on. Here are the various ways to call
`gl.texImage2D` to load data into the texture bound to the currently active unit:

	gl.texImage2D(gl.TEXTURE_2D, 0, format, format, type, image)
	gl.texImage2D(gl.TEXTURE_2D, 0, format, width, height, 0, format, type, data)
	gl.texImage2D(gl.TEXTURE_2D, 0, format, width, height, 0, format, type, null)

Notice that there are some arguments that must be `0`, and the `format` argument has to be given
twice. The two values of `format` must match each other. There's no real reason for this redundancy
within WebGL 1.0 - those arguments that are `0` must really always be `0` - but maybe some future
version will you give the option of changing them.

The `format` argument must be `gl.RGBA`, `gl.RGB`, `gl.ALPHA`, `gl.LUMINANCE`, or
`gl.LUMINANCE_ALPHA`. This argument specifies how many channels of data are saved in the texture,
meaning how many values are saved per pixel. Typically you'll only use `gl.RGBA`, in which case all
four rgba values are saved, or `gl.RGB`, in which case only three values are saved, and alpha values
are ignored. The other formats are occasionally useful, though.

No matter what format you use, when it comes to the shader, you still read 4-channel rgba values
from the texture, they just might be equal to `1.0` no matter what. For instance, if the format of a
texture is `gl.RGB`, any alpha values you read from the texture will automatically be `1.0`.

The `type` argument specifies how many bits are used for each channel. The most common value for
this argument is `gl.UNSIGNED_BYTE`, in which case 8 bits are used for each channel. The
alternatives let you use 1, 4, 5, or 6 bits for different channels, and are only recommended if you
really need to save bytes. I won't go into them.

The last argument to `gl.texImage2D` contains the data you load into the texture. You have three
options here. The first one we use in this lesson is the `image` argument, which is a DOM element of
type `img`, `canvas`, or `video`, or a JavaScript `Image` object. You'll usually use `img` or
`Image` if your texture data is saved a `png` or something somewhere. In this lesson we use `canvas`
to draw a texture with the 2D context. Using `video` will use the current frame of the video as an
image. You can use this for animated textures, but you'll need to keep reloading the data into the
texture whenever the frame changes. With any of these options, you don't need to specify the width
or height. These are taken from the image or video.

Alternately, you can dump an array of raw data into a texture using the `data` argument, which is a
`Uint8Array` (or `Uint16Array` depending on `type`). `Uint8Array` is one of the FixedArray types
that were introduced into JavaScript for WebGL. We'll talk about them more in Lesson XX. The
simplest way to get data into a FixedArray is to create a regular JavaScript Array, and then pass
that to the constructor with `new`:

	var arr = [1, 2, 3, 4]
	var data = new Uint8Array(arr)

You data points should be integers in the range 0 to 255 (that is, unsigned 8-bit integers). WebGL
will automatically convert this into the range 0 to 1 when you read a color from the texture within
the shader.

Finally, you can use `null`, in which case the texture format and size is set up, but no data is
actually loaded. We'll use this option is Lesson 10.

Once you've set up the texture using `gl.texImage2D`, you can also load an image or data array into
a portion of the texture, using `gl.texSubImage2D`:

	gl.texSubImage2D(gl.TEXTURE_2D, 0, x0, y0, format, type, image)
	gl.texSubImage2D(gl.TEXTURE_2D, 0, x0, y0, width, height, format, type, data)

The `format` and `type` arguments must match the arguments used earlier when `gl.texImage2D` was
called.

## Pixel store parameters

As you probably know, even ignoring compression, different image formats have different ways of
storing raw image data. So loading data into a texture is one possible way for data to get messed
up. There are a few pixel store options that handle some common image data storage options. The one
we need for this lesson is `gl.UNPACK_FLIP_Y_WEBGL`. This determines whether the data starts at the
top or the bottom of the image. HTML5 canvas data, like many image formats, starts at the top. But
texture data generally starts at the bottom (I guess that, since you control how the texture is
displayed, you can decide whether to start at the top or the bottom as long as you're consistent,
but I think it makes more sense to stay it starts at the bottom). Therefore we need to set
`gl.UNPACK_FLIP_Y_WEBGL` before loading the canvas data into the texture, so that the rows of data
are reversed as they get loaded into the texture.

	gl.pixelStorei(gl.UNPACK_FLIP_Y_WEBGL, true)

And yes, now we're flipping the y-coordinate twice: once when loading the data into the texture, and
once in the shader:

	mediump vec2 texpos = vec2(gl_PointCoord.x, 1.0 - gl_PointCoord.y);

And yes, they cancel out. You could get rid of both of them if you want (though that might mess
things up when you load raw data into the texture). Anyway, if your textures are coming through
upside down, `gl.UNPACK_FLIP_Y_WEBGL` is one possible fix.

The other pixel store parameters that are available have to do with premultiplied alphas, colorspace
conversion, and data byte alignment. If you're having trouble with any of these when it comes to
loading image data, `gl.pixelStorei` might have a solution.

## Sampler types

So now we know how to bind a texture to a texture unit and load data into it from JavaScript. How do
you read from the texture in the shader? Shaders use the same set of units as JavaScript does, so if
you've bound a texture to the unit `gl.TEXTURE6`, you'll need to look to that unit to read from it.
You do that using a `sampler2D` uniform, and the function `texture2D`:

	uniform sampler2D s;
	uniform vec2 pos;
	void main() {
		gl_FragColor = texture2D(s, pos);

The sampler says which unit to read from, and the `pos` argument says which point on the texture to
read. In this case if we wanted to read from `gl.TEXTURE6`, we would need to set the sampler uniform
to 6 in JavaScript:

	var s = gl.getUniformLocation(prog, "s")
	gl.uniform1i(s, 6)

So what is a sampler, anyway? A `sampler2D` looks like an `int` here, because you use `gl.uniform1i`
to set it. But that's where the similarity ends. Within the shader, samplers are extremely limited
types. Basically all you can do with samplers is:

* declare them as uniforms whose value is set from JavaScript
* use them for lookup in `texture2D`
* pass them as arguments to a function
* use them in uniform arrays and uniform data structures

Things you can't do with a sampler variable include:

* declare them as `const` in the shader
* declare them as vertex attributes or varyings (covered in a later lesson)
* conversions to or from any other type, like `int(s)`
* operations like `s + 1`
* comparisons like `s1 < s2` or `s1 == s2`
* assignments like `s1 = s2`, which means they also can't be `out` or `inout` function parameters

Finally, there are limits on the number of samplers you can have in a single shader. You can't
necessarily use every available unit in every shader. As with other things, the limits required by
WebGL are pretty low, but it's common for there to be more. The required minimums are 0 units
available for vertex shaders (in which case you can't use textures at all in vertex shaders), and 8
units available for fragment shaders.

## Texture lookup

`texture2D(s, pos)` returns a `vec4` color (regardless of the format of the data loaded into the
corresponding texture). The precision of this `vec4` is determined by the precision of `s`. If it
had been declared using `uniform mediump sampler2D s;`, then the return value of `texture2D(s, pos)`
would be `mediump`. However, samplers default to `lowp`, which is fine because colors only need 8
bits of precision.

How about `pos`? Naturally, it means that the color returned will be the color at the specified
position in the texture. Basically, `pos = vec2(0.0, 0.0)` refers to the lower left of the texture,
and `pos = vec2(1.0, 1.0)` refers to the upper right of the texture. You may think there's not much
more to it. You just look up the corresponding pixel, right? Well, there are a ton of subtle issues
when it comes to sampling textures, and exactly what you get back depends on a lot of texture
settings. For this lesson, the only thing we're going to do is set the min filter to `gl.NEAREST`:

	gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.NEAREST)

just because it won't work otherwise (you need to either supply mipmaps or set the min filter).
We'll cover all the options and what they mean in Lesson 09, but that's all you need for this
lesson.

Is it possible to write to a texture from a shader? Sort of, using what's called a framebuffer
object. We'll cover it in a future lesson.

## Getters used in this lesson

	// Number: the largest possible texture is a square of this size
	gl.getParameter(gl.MAX_TEXTURE_SIZE)
	// Number: number of texture units (at least 8)
	gl.getParameter(gl.MAX_COMBINED_TEXTURE_IMAGE_UNITS)
	// Number: maximum number of samplers available to fragment shaders (at least 8)
	gl.getParameter(gl.MAX_TEXTURE_IMAGE_UNITS)
	// Number: maximum number of samplers available to vertex shaders (at least 0)
	gl.getParameter(gl.MAX_VERTEX_TEXTURE_IMAGE_UNITS)
	// boolean: whether this a WebGL texture object
	gl.isTexture(obj)
	// Number (enum): currently active texture unit
	gl.getParameter(gl.ACTIVE_TEXTURE)
	// boolean: whether data is flipped vertically when loaded into a texture
	gl.getParameter(gl.UNPACK_FLIP_Y_WEBGL)

## Exercises

1. Swap the green and blue channels when reading from the texture in the shader. The circle should
switch from orange to pink.
1. Replace all texture unit identifiers like `gl.TEXTURE3` with their corresponding identifiers like
`gl.TEXTURE0 + 3`. Make sure the program still works.
1. Have the program work the same way it does now using only one texture unit, `gl.TEXTURE0`. You'll
need to swap out the two textures between draw commands.
1. Have the program work the same way it does now, but instead of a single sampler uniform that gets
updated, have two sampler uniforms that you set to 3 and 4. Add a boolean uniform that determines
which one to draw.
1. Change the height of `imgcanvas` from 256 to 512. Don't change anything else. Predict how that
will change things. (Note: you'll get an error if you try to change it to a value that's not a power
of 2.)

