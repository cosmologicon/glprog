# Lesson 05

This lesson is a crash course covers the basics of GLSL ES, the language of shaders in WebGL.

## Basic syntax and loops

I won't give a complete description of GLSL, but it's a curly-brace language, with syntax similar to
C and JavaScript. `if` and `else` function the same as in JavaScript. Assignment works the same.
Comments work the same. Arithmetic, bitwise, and logical operators work the same. Statements end in
semicolons and variables need type declarations, like in C. There are, of course, many differences,
but if in doubt, try the syntax you're used to.

Loops are one difference. `for` loops are allowed, but only if the compiler can determine the
number of iterations, and it's not too large. So `for (int i = 0; i < 10; i++)` is fine. But more
complicated setups are not, and you can't modify `i` within the loop body. The reason for this is
that the compiler needs to be able to unroll the loop. In this case, it would replace the loop with
10 copies of its body. When `for` loops are allowed, `break` and `continue` work like in JavaScript.
`while` and `do` loops are not supported.

You might be wondering how it's possible to make complicated 3D scenes with many objects if you
can't even use something as simple as `while` loops in the shaders. The whole idea behind the shader
pipeline is that the main things you would want to iterate over have already been broken out and
parallelized. In some sense, you can think of what goes in the shader as the inner body of a loop
already. The rest of the WebGL state determines how the iteration occurs. If that's not reassuring,
just trust that you'll get the hang of it eventually.

## GLSL variable types

Here are all the variable types in GLSL:

* booleans (`bool`) and boolean vectors (`bvec2`, `bvec3`, `bvec4`)
* integers (`int`) and integer vectors (`ivec2`, `ivec3`, `ivec4`)
* floating point values (`float`) and float vectors (`vec2`, `vec3`, `vec4`)
* floating point square matrices (`mat2`, `mat3`, `mat4`)
* sampler types (`sampler2D`, `samplerCube`)
* 1-dimensional arrays of any of the above values or data structs
* data structs incorporating the above values or other structs

Other OpenGL implementations may have other types, such as non-square matrices and 3D samplers, but
this is all there is for WebGL.

We'll see matrix types in this lesson, and sampler types in Lessons 06 and 07. Booleans are pretty
easy. They're just like in any language. Data structures are also pretty similar to something you
might see in C. They can be useful for organizing large programs, but we're not going to be covering
large enough programs to worry about them.

That leaves arrays. Arrays work basically how you expect, but like `for` loops they have some strict
limitations. They can only be indexed using values that are known to the compiler. You can't index
an array using anything that can be set by outside variables, such as uniforms:

	uniform int i;
	float a[10];
	void main() {
		float x = a[i];  // Illegal!

You should think of GLSL arrays as another kind of data structure, that has N different data members
of the same type. If you do use them, you don't need to worry about out-of-bounds exceptions during
runtime. Since the compiler knows the value every time you index them, out-of-bounds errors are
compile-time errors. Like data structs, these can be useful for organizing large shaders, but I will
not be using arrays.

## Precision

GLSL variables (other than boolean variables) have a precision, which is one of `highp`, `mediump`,
or `lowp`. This is separate from their type. A `mediump int` and a `highp int` are the same type,
and there is automatic conversion between them, unlike between `float` and `int`.

The WebGL specification doesn't say how precise these precisions are. It only sets required minimum
values, and the minimums are pretty low. The required precisions for low, medium, and high precision
values are 8, 10, and 16 bits. For comparison, IEEE single-precision floats have 23 bits of
precision, and double-precision floats (which is the format for JavaScript's Number type) have 52
bits of precision. The precision can also be different in vertex shaders and fragment shaders, as
long as each of them meets the minimum requirements. Furthermore, only vertex shaders are required
to support `highp`. Fragment shaders are only required to support `lowp` and `mediump`, with `highp`
being optional.

Having said that, most implementations exceed the requirements, especially for desktop browsers: the
specification "highly recommends" that `highp` have as much precision as single-precision floats.
I just checked in Chrome, and all three float precisions (even `lowp`) are equivalent to
single-precision floats, and all three integer precisions are equivalent to 32-bit integers, in both
kinds of shaders. Anyway, practically speaking, relatively low precisions are fine for shader math.

The standard practice seems to be to use `highp` in vertex shaders, and `mediump` in fragment
shaders. You would only go below this if you really need to optimize, you know what you're doing,
and you're willing to test on a wide variety of platforms. If you declare and use a uniform variable
in both shaders, though, the precision has to match.

The standard practice is also the built-in default, at least for both floats and ints in vertex
shaders, and ints in fragment shaders. Floats in fragment shaders do not have a built-in default,
and so they must either have a precision declared, or have a default precision declared within their
shader. You can set a default precision for a shader with the `precision` keyword.

	precision highp float;
	precision mediump int;

You can change the default precision multiple throughout the shader, and set a different default
precision within a function or block. Usually, though, you just set it once at the top.

Sampler types also have a precision, which defaults to `lowp`, and can have a default precision set.
But `lowp` is generally fine for samplers. We'll cover them in Lesson 06.

## `gl_FragColor`

Let's start with the fragment shader. As we saw in Lesson 03, the purpose of the fragment shader is
to determine the color that should be drawn at this fragment (which is the same thing as a pixel),
and to write the value to the global variable `gl_FragColor`, which is a `mediump vec4` of rgba
values between 0 and 1.

There's another, similar, output from the fragment shader, called `gl_FragData`. However, it's
useless without certain WebGL extensions. Your WebGL implementation doesn't necessarily support
these extensions (though they are fairly common), and it's a pretty advanced feature, so I won't be
discussing `gl_FragData`.

## `gl_PointCoord` and `discard`

If every fragment writes the same value to `gl_FragColor`, then your point will appear as a square
of a single color. In this lesson we'll see how to let different fragments within the same point
have different colors to produce shaded spheres rather than solid-color squares. The reason we'll do
spheres is because they're simple to work with mathematically. They look the same from any
direction, and their normal vectors are easy to compute.

We want to draw a sphere onto the square point that's passed to the fragment shader. We want to
compute, for every pixel in parallel, what the color should be in order to form a sphere. Now,
how can we have different colors for different pixels if the only inputs into the fragment shader
are uniforms, and those are the same for every fragment? We'll see other ways in later lessons, but
for now we'll use `gl_PointCoord`. This is a `mediump vec2`, a vector of 2 medium-precision floats,
that gives the (x,y) coordinate over the surface of the point. It ranges from (0, 0) in the upper
left of the point to (1, 1) in the lower right of the point. (Note that y = 0 on top, not bottom, in
this case. Usually it's the other way.)

So we want a circle centered at `gl_PointCoord = vec2(0.5, 0.5)` that has a radius of `0.5`. Let's
start by transforming `gl_PointCoord` from something that runs from 0 to 1, to something that runs
from -1 to 1. That way we're looking for a circle centered at (0, 0) with a radius of 1, which is a
little simpler to work with. It has a formula of x^2 + y^2 = 1.

	vec2 r = gl_PointCoord * 2.0 - 1.0;

This may look a little weird if you've worked with vectors in other languages. Multiplying a vector
by `2.0` is normal enough, but what does it mean to subtract `1.0` from a vector? In GLSL, it means
component-wise subtraction. If `v` is a `vec2`, then `v - 1.0` is the same as
`vec2(v.x - 1.0, v.y - 1.0)`.

You'll get used to this sort of thing. Now, once we have the vector `r`, how do we draw the circle?
We want the point to be solid colored within the circle r.x^2 + r.y^2 = 1, and transparent outside
it. One way is to set the alpha value of `gl_FragColor` accordingly:

	gl_FragColor.a = dot(r, r) > 1.0 ? 0.0 : 1.0;

(The `dot` function is the built-in function for the vector dot product. `dot(r, r)` is equal to
`r.x * r.x + r.y * r.y`.) A better way is with the `discard` keyword.

	if (dot(r, r) > 1.0) discard;

This completely throws away this fragment. It won't appear no matter what `gl_FragColor` is, or what
any blending settings are. In this case, we could also use another handy built-in function,
`length`, which is equal to `sqrt(dot(r, r))`:

	if (length(r) > 1.0) discard;

And just like that, we've got a circle.

## Lighting

Let's see this shader actually do some shading. For this, we want a unit normal vector. That is, a
vector with a length of 1 pointing out of the surface. Typically you'll calculate the normal vectors
in JavaScript and pass them in for each vertex, but in this case it's easy enough to calculate.

For a sphere with radius 1, the unit normal vector is the same as a vector from the center of the
sphere to the surface. If we have `r.x` and `r.y`, we can get `r.z` for the vector to the surface,
because we know that for the sphere, r.x^2 + r.y^2 + r.z^2 = 1.

	mediump vec3 r;
	r.xy = gl_PointCoord * 2.0 - 1.0;
	r.z = sqrt(1.0 - dot(r.xy, r.xy));

`r` is now a unit normal vector at this point. Wait a minute, though, when we take the square root,
aren't we in danger of taking the square root of a negative number and crashing the program? No.
First of all, if we did the check earlier, we've already discarded this fragment in the case where
it would be a negative number. But even if we hadn't done that, GLSL is very resiliant to this kind
of thing. It might give you weird results, but it won't crash.

So what do we do with the normal vector? A normal vector tells us which way a surface is facing. If
it's facing toward a light source, we want to make this pixel brighter, and if it's facing in some
other direction, we want to make it darker. We can test whether two vector are pointing in similar
directions by taking their dot product. If `lightpos` is a unit vector pointing toward some light
source, then `dot(r, lightpos)` will be a value between -1 (pointing opposite directions) and 1
(pointing the same direction).

	mediump float shade = 0.4 + 0.6 * dot(r, lightpos);
	shade = clamp(shade, 0.0, 1.0);
	color *= shade;

This generates a value `shade` between -0.2 and 1, restricts it to the range (0, 1) using the
built-in function `clamp`, and then multiplies `color` by the value.

## `gl_FragCoord`

Like `gl_PointCoord`, `gl_FragCoord` is a global value available to the fragment shader that varies
between fragments. It's a `mediump vec4` that gives this fragment's position in the viewport.
`gl_FragCoord.xy` is in pixels. For instance, if the viewport is 854x480 pixels, then
`gl_FragCoord.x` varies from 0 on the left edge to the viewport, to 854 on the right edge.
`gl_FragCoord.y` varies from 0 on the bottom edge, to 480 on the top. `gl_FragCoord.z` indicates the
fragment's depth. Its range is 0 (closest to the viewer) up to 1 (farthest from the viewer),
regardless of viewport size.

Many things you might think to do with `gl_FragCoord` can be better done with shader varyings, which
we'll cover in Lesson 11. But here we use it for two special effects.

First, we use `gl_FragCoord.z` to make things farther from the viewer appear darker, by multiplying
`color` by a value that depends on `gl_FragCoord.z`. (It's a bit subtle, but good effects often
are.) This was a common technique in older video games known as distance fog. Because you could only
render out to a limited distance, by default objects would suddenly appear and disappear as they
passed the distance barrier. So you smoothly blend the object's color into the background color as
it gets farther away, to make the transition less sudden.

Second, we use `gl_FragCoord.xy` to make a circle of inverted colors centered on the mouse cursor.
We pass in the mouse position from JavaScript as a uniform, and use the built-in `distance` function
to invert the color if this fragment's `gl_FragCoord.xy` is close enough to `mpos`.

## Rotation matrices

Now let's look at the vertex shader. The purpose of the vertex shader is to assign a value to the
global `highp vec4 gl_Position`, which is the vertex's position in clip space, and optionally assign
a value to the global `highp float gl_PointSize`, which is the size of the point in pixels.

This vertex shader uses a series of transformations to get the position.

	vec3 gamepos = (vec3(index) - 2.0) / 2.0;


## Coordinate transformations



## Rotation matrices

## Exercises

1. Change the precision of the uniform `index` from `mediump` to `highp`. Remember that it needs to
match in both shaders.
1. Change the vertex shader so that the cube rotates vertically rather than horizontally.
1. Change the fragment shader so that the spheres are backlit.

